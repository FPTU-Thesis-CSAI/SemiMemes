====== evaliuate ======
epoch: 0, global step: 100, val performance  average_precison1: 0.9300641797031681, example_auc1: None,macro_auc1:None,micro_auc1:None,ranking_loss1:0.08369434416365824
=======================
===== best model saved! =======
epoch: 0, global step: 110, loss: 0.478518396247834
====== evaliuate ======
epoch: 1, global step: 200, val performance  average_precison1: 0.9300641797031681, example_auc1: None,macro_auc1:None,micro_auc1:None,ranking_loss1:0.08369434416365824
=======================
epoch: 1, global step: 220, loss: 0.456003283182993
Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']
- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.10it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:15<00:00,  1.46it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:11<00:00,  2.00it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:13<00:00,  1.50it/s]
 12%|███████████████▏                                                                                                                 | 13/110 [00:07<00:56,  1.71it/s]
Traceback (most recent call last):
  File "/content/SSLMemes/src/train.py", line 280, in <module>
    step_global=global_step, epoch=epoch, val_best_score=val_best_score, processor=processor)
  File "/content/SSLMemes/src/train.py", line 83, in train
    scaler.scale(loss).backward()
  File "/usr/local/lib/python3.7/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt