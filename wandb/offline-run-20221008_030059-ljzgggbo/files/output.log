score for class 1:0.5102624893188477, class 2:0.49946117401123047, class 3:0.4777511954307556, class 4:0.4336913228034973,avg score:0.48029154539108276
====== evaliuate ======
epoch: 0, global step: 100, val performance: 0.3446666666666667, auc: 0.48029154539108276
=======================
===== best model saved! =======
epoch: 0, global step: 110, loss: 0.478518396247834
score for class 1:0.5238800048828125, class 2:0.5069185495376587, class 3:0.5307899713516235, class 4:0.5309040546417236,avg score:0.5231231451034546
====== evaliuate ======
epoch: 1, global step: 200, val performance: 0.3446666666666667, auc: 0.5231231451034546
=======================
epoch: 1, global step: 220, loss: 0.456003283182993
score for class 1:0.5186491012573242, class 2:0.5146582126617432, class 3:0.5312693119049072, class 4:0.5175224542617798,avg score:0.5205247402191162
====== evaliuate ======
epoch: 2, global step: 300, val performance: 0.3446666666666667, auc: 0.5205247402191162
=======================
epoch: 2, global step: 330, loss: 0.45509770210995415
score for class 1:0.5384784936904907, class 2:0.5050073266029358, class 3:0.5472453236579895, class 4:0.5164884924888611,avg score:0.5268049240112305
====== evaliuate ======
epoch: 3, global step: 400, val performance: 0.3446666666666667, auc: 0.5268049240112305
=======================
epoch: 3, global step: 440, loss: 0.45473793243201566
score for class 1:0.5409591197967529, class 2:0.49921369552612305, class 3:0.5546442270278931, class 4:0.5243856310844421,avg score:0.5298006534576416
====== evaliuate ======
epoch: 4, global step: 500, val performance: 0.3446666666666667, auc: 0.5298006534576416
=======================
epoch: 4, global step: 550, loss: 0.4535941359395628
You are using a model of type visual_bert to instantiate a model of type lxmert. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']
- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.87it/s]
/usr/local/lib/python3.7/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUROC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.
  warnings.warn(*args, **kwargs)
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:22<00:00,  1.33it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.91it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:18<00:00,  1.41it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.90it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:18<00:00,  1.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.90it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:18<00:00,  1.40it/s]
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.90it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:18<00:00,  1.41it/s]
 14%|█████████████████▌                                                                                                               | 15/110 [00:08<00:56,  1.67it/s]
Traceback (most recent call last):
  File "/content/SSLMemes/src/train.py", line 312, in <module>
    step_global=global_step, epoch=epoch, val_best_score=val_best_score, processor=processor)
  File "/content/SSLMemes/src/train.py", line 81, in train
    scaler.scale(loss).backward()
  File "/usr/local/lib/python3.7/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt