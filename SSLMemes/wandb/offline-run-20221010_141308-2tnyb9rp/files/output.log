====== evaliuate ======
epoch: 0, global step: 100, val performance -
 average_precison1: 0.9300641797031681
 example_auc1: 0.9163056558363418
 macro_auc1:0.4802897481234984
 micro_auc1:0.8365172064299948
 ranking_loss1:0.08369434416365824
=======================
===== best model saved! =======
epoch: 0, global step: 110, loss: 0.478518396247834
Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.91it/s]
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110/110 [01:21<00:00,  1.36it/s]
 45%|█████████████████████████████████████████████████████████▍                                                                       | 49/110 [00:27<00:34,  1.75it/s]
Traceback (most recent call last):
  File "/content/SSLMemes/src/train.py", line 280, in <module>
    step_global=global_step, epoch=epoch, val_best_score=val_best_score, processor=processor)
  File "/content/SSLMemes/src/train.py", line 83, in train
    scaler.scale(loss).backward()
  File "/usr/local/lib/python3.7/dist-packages/torch/tensor.py", line 245, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py", line 147, in backward
    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag
KeyboardInterrupt