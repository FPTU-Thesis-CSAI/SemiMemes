You are using a model of type visual_bert to instantiate a model of type lxmert. This is not supported for all configurations of models and can yield errors.
Some weights of the model checkpoint at uclanlp/visualbert-nlvr2-coco-pre were not used when initializing VisualBertModel: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias']
- This IS expected if you are initializing VisualBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing VisualBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:12<00:00,  1.91it/s]
 90%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████             | 99/110 [01:13<00:08,  1.34it/s]
Traceback (most recent call last):
  File "/content/SSLMemes/src/train.py", line 312, in <module>
    step_global=global_step, epoch=epoch, val_best_score=val_best_score, processor=processor)
  File "/content/SSLMemes/src/train.py", line 121, in train
    acc, _, _, _,auc = evaluate(val_loader, model, model_type=model_type)
  File "/content/SSLMemes/src/eval.py", line 74, in evaluate
    #print (y != torch.argmax(scores, dim=1))
RuntimeError: stack expects each tensor to be equal size, but got [64, 4] at entry 0 and [28, 4] at entry 23